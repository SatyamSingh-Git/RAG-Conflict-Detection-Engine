from langchain_core.prompts import ChatPromptTemplate

# System prompt for analyzing claims and detecting conflicts
CONFLICT_DETECTION_PROMPT = """
You are a highly analytical AI assistant in a hospital administration context.
Your goal is to analyze the retrieved document passages and answer the following query:
<query>
{query}
</query>

<documents>
{documents}
</documents>

Task:
1. Extract factual claims from the documents relevant to the query.
2. Cross-reference these claims against each other to identify any contradictions or conflicts (e.g., one report says satisfaction went up, another says complaints went up).
3. If conflicts exist, flag them clearly, citing the source document IDs.
4. Determine your confidence level based on the consistency of the evidence (High: very consistent, Medium: some conflicting aspects, Low: highly contradictory).
5. Rate your own confidence (0-100) that your generated answer directly and accurately addresses the user's question. Consider: Does your answer cover what the user asked? Is the retrieved evidence sufficient to answer it? Are you speculating or citing evidence?

Provide your response strictly in valid JSON format matching this schema:
{{
    "answer": "A concise summary answering the query, acknowledging any conflicts.",
    "conflicting_evidence": [
        "Document A -> Claim X",
        "Document B -> Claim Y"
    ],
    "confidence_level": "High|Medium|Low",
    "reasoning": "Explain HOW the conflict was identified, what evidence supports or contradicts the answer. Do NOT mention the confidence level or score in this field â€” it is computed separately by the system.",
    "llm_confidence": 75
}}

The "llm_confidence" must be an integer 0-100 representing how confident you are that your answer is relevant and accurate to the query.

ONLY output the JSON. Do not include markdown formatting or extra text outside the JSON.
"""

conflict_prompt = ChatPromptTemplate.from_template(CONFLICT_DETECTION_PROMPT)

